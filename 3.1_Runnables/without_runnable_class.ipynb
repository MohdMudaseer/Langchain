{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00aad7b",
   "metadata": {},
   "source": [
    "## Runnables\n",
    ">In LangChain, Runnables are the core abstraction for executing and composing units of work (like chains, LLM calls, retrievers, tools, prompts, etc.).<Br>\n",
    "\n",
    "### 1. Task-specific Runnables\n",
    "> These are runnables that perform a single concrete function (atomic units).<BR>\n",
    ">Examples:<BR>\n",
    ">LLMs â†’ ChatOpenAI, ChatGroq, ChatAnthropic<BR>\n",
    ">Prompts â†’ ChatPromptTemplate, PromptTemplate<BR>\n",
    "?Retrievers â†’ for fetching docs from a vector store (like FAISS, Pinecone)<BR>\n",
    ">Document Transformers â†’ summarizers, splitters, re-rankers<BR>\n",
    ">Tools/Functions â†’ e.g., a calculator, API call wrapper, or your own Python function wrapped as a runnable<BR>\n",
    "ðŸ‘‰ Theyâ€™re like individual workers who each do one task.<BR>\n",
    "\n",
    "### 2. Composition/Connector Runnables(Runnable Primitives)\n",
    "\n",
    ">These are runnables that connect or combine multiple task-specific runnables into workflows.<BR>\n",
    ">Examples:<BR>\n",
    ">Piping (|) â†’ chaining runnables in sequence<BR>\n",
    ">RunnableMap â†’ send input to multiple runnables at once (parallel execution)<BR>\n",
    ">RunnableParallel â†’ execute tasks in true parallel<BR>\n",
    ">RunnableBranch â†’ conditionally pick which runnable to execute<BR>\n",
    ">RunnableSequence â†’ explicitly define sequential steps<BR>\n",
    "ðŸ‘‰ Theyâ€™re like managers/coordinators who arrange how workers collaborate.<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d23afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class NakliLLM:\n",
    "    def __init__(self):\n",
    "        print(\"LLM created\")\n",
    "\n",
    "    def predict(self,prompt):\n",
    "        list=[\n",
    "            \"Delhi is the capital of India\",\n",
    "            \"AI stands for Artificial Intelligence\",\n",
    "            \"Beauty lies in the eyes of the beholder\"\n",
    "        ]\n",
    "        return {'response': random.choice(list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5418ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NakliPromptTemplate:\n",
    "    def __init__(self,template,input_variables):\n",
    "        self.template=template\n",
    "        self.input_variables=input_variables\n",
    "    def format(self,input_dict):\n",
    "        return self.template.format(**input_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e76099",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = NakliPromptTemplate(\n",
    "    template='Write a {length} poem about {topic}',\n",
    "    input_variables=['length', 'topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8539e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=template.format({\"length\": \"short\", \"topic\": \"friendship\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3b647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    }
   ],
   "source": [
    "llm=NakliLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3592dee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'AI stands for Artificial Intelligence'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58a1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NakliLLMChain:\n",
    "    def __init__(self,llm,prompt):\n",
    "        self.llm=llm\n",
    "        self.prompt=prompt\n",
    "    def run(self,input_dict):\n",
    "        format_prompt=self.prompt.format(input_dict)\n",
    "        return self.llm.predict(prompt=format_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d19313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n",
      "{'response': 'Beauty lies in the eyes of the beholder'}\n"
     ]
    }
   ],
   "source": [
    "llm=NakliLLM()\n",
    "template=NakliPromptTemplate(\n",
    "    template='Write a {length} poem about {topic}',\n",
    "    input_variables=['length', 'topic']\n",
    ")\n",
    "chain=NakliLLMChain(llm=llm,prompt=template)\n",
    "print(chain.run({\"length\": \"short\", \"topic\": \"friendship\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
